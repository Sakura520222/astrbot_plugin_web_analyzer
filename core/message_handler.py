# -*- coding: utf-8 -*-
"""
æ¶ˆæ¯å¤„ç†æ¨¡å—

è´Ÿè´£å¤„ç†å•ä¸ªå’Œæ‰¹é‡ URL åˆ†æã€å‘é€åˆ†æç»“æœç­‰ã€‚
"""

import os
import sys
import tempfile
from pathlib import Path
from typing import Any

# ç¡®ä¿çˆ¶ç›®å½•åœ¨ Python è·¯å¾„ä¸­
parent_dir = Path(__file__).parent.parent
if str(parent_dir) not in sys.path:
    sys.path.insert(0, str(parent_dir))

from astrbot.api import logger
from astrbot.api.event import AstrMessageEvent
from astrbot.api.message_components import Image, Node, Nodes, Plain

from analyzer import WebAnalyzer
from cache import CacheManager
from core.constants import ErrorType
from core.error_handler import ErrorHandler


class MessageHandler:
    """æ¶ˆæ¯å¤„ç†å™¨ç±»"""

    def __init__(
        self,
        analyzer: WebAnalyzer,
        cache_manager: CacheManager,
        enable_cache: bool = True,
        enable_screenshot: bool = True,
        send_content_type: str = "both",
        screenshot_format: str = "jpeg",
    ):
        """åˆå§‹åŒ–æ¶ˆæ¯å¤„ç†å™¨

        Args:
            analyzer: WebAnalyzer å®ä¾‹
            cache_manager: CacheManager å®ä¾‹
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            enable_screenshot: æ˜¯å¦å¯ç”¨æˆªå›¾
            send_content_type: å‘é€å†…å®¹ç±»å‹
            screenshot_format: æˆªå›¾æ ¼å¼
        """
        self.analyzer = analyzer
        self.cache_manager = cache_manager
        self.enable_cache = enable_cache
        self.enable_screenshot = enable_screenshot
        self.send_content_type = send_content_type
        self.screenshot_format = screenshot_format

    def check_cache(self, url: str) -> dict | None:
        """æ£€æŸ¥æŒ‡å®š URL çš„ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ

        Args:
            url: ç½‘é¡µ URL

        Returns:
            ç¼“å­˜ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨æˆ–æ— æ•ˆåˆ™è¿”å› None
        """
        if not self.enable_cache:
            return None

        normalized_url = self.analyzer.normalize_url(url)
        return self.cache_manager.get(normalized_url)

    def update_cache(self, url: str, result: dict, content: str = None):
        """æ›´æ–°æŒ‡å®š URL çš„ç¼“å­˜

        Args:
            url: ç½‘é¡µ URL
            result: åˆ†æç»“æœ
            content: ç½‘é¡µå†…å®¹ï¼ˆå¯é€‰ï¼Œç”¨äºå†…å®¹å“ˆå¸Œç¼“å­˜ï¼‰
        """
        if not self.enable_cache:
            return

        normalized_url = self.analyzer.normalize_url(url)

        if content:
            self.cache_manager.set_with_content_hash(normalized_url, result, content)
        else:
            self.cache_manager.set(normalized_url, result)

    async def process_single_url(
        self,
        event: AstrMessageEvent,
        url: str,
        analyzer: WebAnalyzer,
        llm_analyzer=None,
        enable_translation=False,
        enable_specific_extraction=False,
        extract_types=None,
        result_formatter=None,
    ) -> dict:
        """å¤„ç†å•ä¸ªç½‘é¡µ URLï¼Œç”Ÿæˆå®Œæ•´çš„åˆ†æç»“æœ

        Args:
            event: æ¶ˆæ¯äº‹ä»¶å¯¹è±¡
            url: ç½‘é¡µ URL
            analyzer: WebAnalyzer å®ä¾‹
            llm_analyzer: LLMAnalyzer å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            enable_translation: æ˜¯å¦å¯ç”¨ç¿»è¯‘
            enable_specific_extraction: æ˜¯å¦å¯ç”¨ç‰¹å®šå†…å®¹æå–
            extract_types: æå–ç±»å‹åˆ—è¡¨
            result_formatter: ResultFormatter å®ä¾‹ï¼ˆå¯é€‰ï¼‰

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            # 1. æ£€æŸ¥ç¼“å­˜
            cached_result = self.check_cache(url)
            if cached_result:
                logger.info(f"ä½¿ç”¨ URL ç¼“å­˜ç»“æœ: {url}")
                return cached_result

            # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿æ‰€æœ‰æ“ä½œéƒ½åœ¨åŒä¸€ä¸ª HTTP å®¢æˆ·ç«¯ä¸­å®Œæˆ
            async with analyzer:
                # 2. æŠ“å–ç½‘é¡µå†…å®¹
                html = await analyzer.fetch_webpage(url)
                if not html:
                    error_msg = ErrorHandler.handle_error(
                        ErrorType.NETWORK_ERROR, Exception("æ— æ³•è·å–ç½‘é¡µå†…å®¹"), url
                    )
                    return {"url": url, "result": error_msg, "screenshot": None}

                # 3. æå–ç»“æ„åŒ–å†…å®¹
                content_data = analyzer.extract_content(html, url)
                if not content_data:
                    error_msg = ErrorHandler.handle_error(
                        ErrorType.PARSING_ERROR, Exception("æ— æ³•è§£æç½‘é¡µå†…å®¹"), url
                    )
                    return {"url": url, "result": error_msg, "screenshot": None}

                # 4. è°ƒç”¨ LLM è¿›è¡Œåˆ†æ
                analysis_result = await self._analyze_content(
                    event, content_data, llm_analyzer, enable_translation
                )

                # 5. æå–ç‰¹å®šå†…å®¹
                if enable_specific_extraction and extract_types:
                    analysis_result = await self._extract_and_add_specific_content(
                        analysis_result, html, url, extract_types
                    )

                # 6. ç”Ÿæˆæˆªå›¾
                screenshot = await self._generate_screenshot(
                    analyzer, url, analysis_result
                )

                # 7. å‡†å¤‡ç»“æœæ•°æ®
                result_data = {
                    "url": url,
                    "result": analysis_result,
                    "screenshot": screenshot,
                }

                # 8. æ›´æ–°ç¼“å­˜
                self.update_cache(url, result_data, content_data["content"])

                return result_data
        except Exception as e:
            error_type = ErrorHandler.get_error_type(e)
            error_msg = ErrorHandler.handle_error(error_type, e, url)
            return {"url": url, "result": error_msg, "screenshot": None}

    async def _fetch_webpage_content(self, analyzer: WebAnalyzer, url: str) -> str:
        """æŠ“å–ç½‘é¡µ HTML å†…å®¹

        Args:
            analyzer: WebAnalyzer å®ä¾‹
            url: è¦æŠ“å–çš„ URL

        Returns:
            ç½‘é¡µ HTML å†…å®¹
        """
        try:
            # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿ client è¢«æ­£ç¡®åˆå§‹åŒ–
            async with analyzer:
                html = await analyzer.fetch_webpage(url)
                return html
        except Exception as e:
            logger.error(f"æŠ“å–ç½‘é¡µå¤±è´¥: {url}, é”™è¯¯: {e}")
            return ""

    async def _extract_structured_content(
        self, analyzer: WebAnalyzer, html: str, url: str
    ) -> dict | None:
        """ä» HTML ä¸­æå–ç»“æ„åŒ–å†…å®¹

        Args:
            analyzer: WebAnalyzer å®ä¾‹
            html: ç½‘é¡µ HTML å†…å®¹
            url: ç½‘é¡µ URL

        Returns:
            åŒ…å«ç»“æ„åŒ–å†…å®¹çš„å­—å…¸
        """
        try:
            content_data = analyzer.extract_content(html, url)
            return content_data
        except Exception as e:
            logger.error(f"æå–ç»“æ„åŒ–å†…å®¹å¤±è´¥: {url}, é”™è¯¯: {e}")
            return None

    async def _analyze_content(
        self, event: AstrMessageEvent, content_data: dict, llm_analyzer, enable_translation: bool
    ) -> str:
        """è°ƒç”¨ LLM æˆ–åŸºç¡€åˆ†ææ–¹æ³•åˆ†æå†…å®¹

        Args:
            event: æ¶ˆæ¯äº‹ä»¶å¯¹è±¡
            content_data: ç»“æ„åŒ–å†…å®¹æ•°æ®
            llm_analyzer: LLMAnalyzer å®ä¾‹
            enable_translation: æ˜¯å¦å¯ç”¨ç¿»è¯‘

        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        try:
            # å¦‚æœæœ‰ LLM åˆ†æå™¨ï¼Œä½¿ç”¨ LLM åˆ†æ
            if llm_analyzer:
                result = await llm_analyzer.analyze_with_llm(event, content_data)
                if result:
                    return result

            # å¦åˆ™è¿”å›åŸºç¡€åˆ†æ
            # è¿™é‡Œéœ€è¦ result_formatterï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç®€å•æ‘˜è¦
            return f"ç½‘é¡µæ ‡é¢˜ï¼š{content_data.get('title', 'æ— æ ‡é¢˜')}\n\nå†…å®¹ï¼š{content_data.get('content', '')[:500]}..."
        except Exception as e:
            logger.error(f"åˆ†æå†…å®¹å¤±è´¥: {content_data.get('url', '')}, é”™è¯¯: {e}")
            return "åˆ†æå¤±è´¥"

    async def _extract_and_add_specific_content(
        self, analysis_result: str, html: str, url: str, extract_types: list
    ) -> str:
        """æå–ç‰¹å®šç±»å‹å†…å®¹å¹¶æ·»åŠ åˆ°åˆ†æç»“æœä¸­

        Args:
            analysis_result: å½“å‰çš„åˆ†æç»“æœ
            html: ç½‘é¡µ HTML å†…å®¹
            url: ç½‘é¡µ URL
            extract_types: æå–ç±»å‹åˆ—è¡¨

        Returns:
            æ›´æ–°åçš„åˆ†æç»“æœ
        """
        try:
            specific_content = self.analyzer.extract_specific_content(
                html, url, extract_types
            )
            if not specific_content:
                return analysis_result

            # åœ¨åˆ†æç»“æœä¸­æ·»åŠ ç‰¹å®šå†…å®¹
            specific_content_str = "\n\n**ç‰¹å®šå†…å®¹æå–**\n"

            # æ·»åŠ å›¾ç‰‡é“¾æ¥
            if "images" in specific_content and specific_content["images"]:
                specific_content_str += (
                    f"\nğŸ“· å›¾ç‰‡é“¾æ¥ ({len(specific_content['images'])}):\n"
                )
                for img in specific_content["images"]:
                    img_url = img.get("url", "")
                    alt_text = img.get("alt", "")
                    if alt_text:
                        specific_content_str += f"- {img_url} (alt: {alt_text})\n"
                    else:
                        specific_content_str += f"- {img_url}\n"

            # æ·»åŠ ç›¸å…³é“¾æ¥
            if "links" in specific_content and specific_content["links"]:
                specific_content_str += (
                    f"\nğŸ”— ç›¸å…³é“¾æ¥ ({len(specific_content['links'])}):\n"
                )
                for link in specific_content["links"][:5]:
                    specific_content_str += f"- [{link['text']}]({link['url']})\n"

            return analysis_result + specific_content_str
        except Exception as e:
            logger.warning(f"ç‰¹å®šå†…å®¹æå–å¤±è´¥: {url}, é”™è¯¯: {e}")
            return analysis_result

    async def _generate_screenshot(
        self, analyzer: WebAnalyzer, url: str, analysis_result: str
    ) -> bytes | None:
        """ç”Ÿæˆç½‘é¡µæˆªå›¾

        Args:
            analyzer: WebAnalyzer å®ä¾‹
            url: ç½‘é¡µ URL
            analysis_result: å½“å‰çš„åˆ†æç»“æœ

        Returns:
            æˆªå›¾äºŒè¿›åˆ¶æ•°æ®
        """
        if not self.enable_screenshot or self.send_content_type == "analysis_only":
            return None

        try:
            # è¿™é‡Œéœ€è¦ä¼ å…¥æˆªå›¾å‚æ•°ï¼Œæš‚æ—¶ä½¿ç”¨é»˜è®¤å€¼
            screenshot = await analyzer.capture_screenshot(url)
            return screenshot
        except Exception as e:
            logger.error(f"æˆªå›¾å¤±è´¥: {url}, é”™è¯¯: {e}")
            return None

    async def send_analysis_result(self, event: AstrMessageEvent, analysis_results: list):
        """å‘é€åˆ†æç»“æœ

        Args:
            event: æ¶ˆæ¯äº‹ä»¶å¯¹è±¡
            analysis_results: åˆ†æç»“æœåˆ—è¡¨

        Yields:
            æ¶ˆæ¯ç»“æœ
        """
        if not analysis_results:
            logger.info("æ²¡æœ‰åˆ†æç»“æœï¼Œä¸å‘é€æ¶ˆæ¯")
            return

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç»“æœéƒ½æ˜¯é”™è¯¯ç»“æœ
        all_errors = True
        for result in analysis_results:
            if result.get("screenshot"):
                all_errors = False
                break
            result_text = result.get("result", "")
            if not any(keyword in result_text for keyword in ["å¤±è´¥", "é”™è¯¯", "æ— æ³•", "âŒ"]):
                all_errors = False
                break

        if all_errors:
            logger.info("æ‰€æœ‰ URL åˆ†æå¤±è´¥ï¼Œä¸å‘é€æ¶ˆæ¯")
            return

        try:
            for i, result_data in enumerate(analysis_results, 1):
                screenshot = result_data.get("screenshot")
                analysis_result = result_data.get("result")

                # å‘é€åˆ†æç»“æœæ–‡æœ¬
                if self.send_content_type != "screenshot_only" and analysis_result:
                    if len(analysis_results) == 1:
                        result_text = f"ç½‘é¡µåˆ†æç»“æœï¼š\n{analysis_result}"
                    else:
                        result_text = f"ç¬¬{i}/{len(analysis_results)}ä¸ªç½‘é¡µåˆ†æç»“æœï¼š\n{analysis_result}"
                    yield event.plain_result(result_text)

                # å‘é€æˆªå›¾
                if screenshot and self.send_content_type != "analysis_only":
                    try:
                        suffix = f".{self.screenshot_format}" if self.screenshot_format else ".jpg"
                        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as temp_file:
                            temp_file.write(screenshot)
                            temp_file_path = temp_file.name

                        image_component = Image.fromFileSystem(temp_file_path)
                        yield event.chain_result([image_component])
                        logger.info("å‘é€åˆ†æç»“æœå’Œæˆªå›¾")

                        os.unlink(temp_file_path)
                    except Exception as e:
                        logger.error(f"å‘é€æˆªå›¾å¤±è´¥: {e}")
                        if "temp_file_path" in locals() and os.path.exists(temp_file_path):
                            os.unlink(temp_file_path)
        except Exception as e:
            logger.error(f"å‘é€åˆ†æç»“æœå¤±è´¥: {e}")
            yield event.plain_result(f"âŒ å‘é€åˆ†æç»“æœå¤±è´¥: {str(e)}")