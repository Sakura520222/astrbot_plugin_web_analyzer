
"""
ç»“æœæ ¼å¼åŒ–æ¨¡å—

è´Ÿè´£æ ¼å¼åŒ–åˆ†æç»“æœã€åº”ç”¨æ¨¡æ¿ã€æŠ˜å é•¿å†…å®¹ç­‰ã€‚
"""

from datetime import datetime


class ResultFormatter:
    """ç»“æœæ ¼å¼åŒ–å™¨ç±»"""

    def __init__(self, enable_emoji: bool = True, enable_statistics: bool = True):
        """åˆå§‹åŒ–ç»“æœæ ¼å¼åŒ–å™¨

        Args:
            enable_emoji: æ˜¯å¦å¯ç”¨emoji
            enable_statistics: æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        """
        self.enable_emoji = enable_emoji
        self.enable_statistics = enable_statistics

    def apply_result_settings(
        self, result: str, url: str, content_data: dict = None, **kwargs
    ) -> str:
        """åº”ç”¨æ‰€æœ‰ç»“æœè®¾ç½®ï¼ˆæ¨¡æ¿æ¸²æŸ“å’ŒæŠ˜å ï¼‰

        Args:
            result: åˆ†æç»“æœ
            url: ç½‘é¡µURL
            content_data: å†…å®¹æ•°æ®ï¼ˆå¯é€‰ï¼‰
            **kwargs: å…¶ä»–é…ç½®å‚æ•°

        Returns:
            æ ¼å¼åŒ–åçš„ç»“æœ
        """
        enable_custom_template = kwargs.get("enable_custom_template", False)
        result_template = kwargs.get("result_template", "default")
        enable_collapsible = kwargs.get("enable_collapsible", False)
        collapse_threshold = kwargs.get("collapse_threshold", 1500)
        template_content = kwargs.get("template_content", "")

        # é¦–å…ˆåº”ç”¨æ¨¡æ¿æ¸²æŸ“
        if enable_custom_template and content_data:
            rendered_result = self._render_custom_template(
                content_data, result, url, template_content
            )
        else:
            rendered_result = self._render_result_template(result, url, result_template)

        # ç„¶ååº”ç”¨ç»“æœæŠ˜å 
        final_result = self._collapse_result(
            rendered_result, enable_collapsible, collapse_threshold
        )

        return final_result

    def _render_result_template(self, result: str, url: str, template_type: str) -> str:
        """æ ¹æ®æ¨¡æ¿ç±»å‹æ¸²æŸ“åˆ†æç»“æœ

        Args:
            result: åˆ†æç»“æœ
            url: ç½‘é¡µURL
            template_type: æ¨¡æ¿ç±»å‹

        Returns:
            æ¸²æŸ“åçš„ç»“æœ
        """
        if template_type == "detailed":
            return (
                f"ã€è¯¦ç»†åˆ†æç»“æœã€‘\n\nğŸ“Œ åˆ†æURLï¼š{url}\n\n{result}\n\n--- åˆ†æç»“æŸ ---"
            )
        elif template_type == "compact":
            lines = result.splitlines()
            compact_result = []
            for line in lines:
                if line.strip() and not line.startswith("âš ï¸"):
                    compact_result.append(line)
                    if len(compact_result) >= 10:
                        break
            return (
                f"ã€ç´§å‡‘åˆ†æç»“æœã€‘\n{url}\n\n"
                + "\n".join(compact_result)
                + "\n\n... æ›´å¤šå†…å®¹è¯·æŸ¥çœ‹å®Œæ•´åˆ†æ"
            )
        elif template_type == "markdown":
            return f"# ç½‘é¡µåˆ†æç»“æœ\n\n## URL\n{url}\n\n## åˆ†æå†…å®¹\n{result}\n\n---\n*åˆ†æå®Œæˆäº {self._get_current_time()}*"
        elif template_type == "simple":
            return f"{url}\n\n{result}"
        else:
            return f"ã€ç½‘é¡µåˆ†æç»“æœã€‘\n{url}\n\n{result}"

    def _render_custom_template(
        self, content_data: dict, analysis_result: str, url: str, template_content: str
    ) -> str:
        """ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿æ¸²æŸ“åˆ†æç»“æœ

        Args:
            content_data: åŒ…å«æ ‡é¢˜ã€å†…å®¹ç­‰ä¿¡æ¯çš„å­—å…¸
            analysis_result: å½“å‰çš„åˆ†æç»“æœ
            url: ç½‘é¡µURL
            template_content: æ¨¡æ¿å†…å®¹

        Returns:
            æ¸²æŸ“åçš„ç»“æœ
        """
        now = datetime.now()
        date_str = now.strftime("%Y-%m-%d")
        time_str = now.strftime("%H:%M:%S")

        content = content_data.get("content", "")
        content_stats = self._calculate_content_statistics(content)

        stats_str = """
- å­—ç¬¦æ•°: {char_count:,}
- è¯æ•°: {word_count:,}
- æ®µè½æ•°: {paragraph_count}
"""
        paragraph_count = len([p.strip() for p in content.split("\n") if p.strip()])
        stats = stats_str.format(
            char_count=content_stats["char_count"],
            word_count=content_stats["word_count"],
            paragraph_count=paragraph_count,
        )

        summary = content[:150] + "..." if len(content) > 150 else content
        content_type = self._detect_content_type(content)

        template_vars = {
            "title": content_data.get("title", "æ— æ ‡é¢˜"),
            "url": url,
            "content": content,
            "summary": summary,
            "analysis_result": analysis_result,
            "screenshot": "[æˆªå›¾]",
            "content_type": content_type,
            "stats": stats,
            "date": date_str,
            "time": time_str,
        }

        rendered_template = template_content
        for var_name, var_value in template_vars.items():
            rendered_template = rendered_template.replace(f"{{{var_name}}}", str(var_value))

        return rendered_template

    def _collapse_result(
        self, result: str, enable_collapsible: bool, collapse_threshold: int
    ) -> str:
        """æ ¹æ®é…ç½®æŠ˜å é•¿ç»“æœ

        Args:
            result: åˆ†æç»“æœ
            enable_collapsible: æ˜¯å¦å¯ç”¨æŠ˜å 
            collapse_threshold: æŠ˜å é˜ˆå€¼

        Returns:
            æŠ˜å åçš„ç»“æœ
        """
        if enable_collapsible and len(result) > collapse_threshold:
            collapse_pos = collapse_threshold
            while collapse_pos < len(result) and result[collapse_pos] != "\n":
                collapse_pos += 1
            if collapse_pos == len(result):
                collapse_pos = collapse_threshold

            collapsed_content = result[:collapse_pos]
            remaining_content = result[collapse_pos:]
            return f"{collapsed_content}\n\n[å±•å¼€å…¨æ–‡]\n\n{remaining_content}"
        return result

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _calculate_content_statistics(self, content: str) -> dict:
        """è®¡ç®—å†…å®¹ç»Ÿè®¡ä¿¡æ¯"""
        char_count = len(content)
        word_count = len(content.split())
        return {"char_count": char_count, "word_count": word_count}

    def _detect_content_type(self, content: str) -> str:
        """æ™ºèƒ½æ£€æµ‹å†…å®¹ç±»å‹"""
        content_lower = content.lower()
        rules = self._get_content_type_rules()

        for type_name, keywords in rules.items():
            if any(keyword in content_lower for keyword in keywords):
                return type_name
        return "æ–‡ç« "

    def _get_content_type_rules(self) -> dict[str, list[str]]:
        """è·å–å†…å®¹ç±»å‹æ£€æµ‹è§„åˆ™"""
        return {
            "æ–°é—»èµ„è®¯": [
                "æ–°é—»",
                "æŠ¥é“",
                "æ¶ˆæ¯",
                "æ—¶äº‹",
                "å¿«è®¯",
                "å¤´æ¡",
                "è¦é—»",
                "çƒ­ç‚¹",
                "äº‹ä»¶",
            ],
            "æ•™ç¨‹æŒ‡å—": [
                "æ•™ç¨‹",
                "æŒ‡å—",
                "æ•™å­¦",
                "æ­¥éª¤",
                "æ–¹æ³•",
                "å¦‚ä½•",
                "æ€æ ·",
                "æ”»ç•¥",
                "æŠ€å·§",
            ],
            "ä¸ªäººåšå®¢": [
                "åšå®¢",
                "éšç¬”",
                "æ—¥è®°",
                "ä¸ªäºº",
                "è§‚ç‚¹",
                "æ„Ÿæƒ³",
                "æ„Ÿæ‚Ÿ",
                "æ€è€ƒ",
                "åˆ†äº«",
            ],
            "äº§å“ä»‹ç»": [
                "äº§å“",
                "æœåŠ¡",
                "è´­ä¹°",
                "ä»·æ ¼",
                "ä¼˜æƒ ",
                "åŠŸèƒ½",
                "ç‰¹æ€§",
                "å‚æ•°",
                "è§„æ ¼",
                "è¯„æµ‹",
            ],
            "æŠ€æœ¯æ–‡æ¡£": ["æŠ€æœ¯", "å¼€å‘", "ç¼–ç¨‹", "ä»£ç ", "API", "SDK", "æ–‡æ¡£", "è¯´æ˜"],
            "å­¦æœ¯è®ºæ–‡": [
                "è®ºæ–‡",
                "ç ”ç©¶",
                "å®éªŒ",
                "ç»“è®º",
                "æ‘˜è¦",
                "å…³é”®è¯",
                "å¼•ç”¨",
                "å‚è€ƒæ–‡çŒ®",
            ],
            "å•†ä¸šåˆ†æ": [
                "åˆ†æ",
                "æŠ¥å‘Š",
                "æ•°æ®",
                "ç»Ÿè®¡",
                "è¶‹åŠ¿",
                "é¢„æµ‹",
                "å¸‚åœº",
                "è¡Œä¸š",
            ],
            "å¨±ä¹èµ„è®¯": [
                "å¨±ä¹",
                "æ˜æ˜Ÿ",
                "ç”µå½±",
                "éŸ³ä¹",
                "ç»¼è‰º",
                "æ¼”å”±ä¼š",
                "é¦–æ˜ ",
                "æ–°æ­Œ",
            ],
            "ä½“è‚²æ–°é—»": [
                "ä½“è‚²",
                "æ¯”èµ›",
                "èµ›äº‹",
                "æ¯”åˆ†",
                "è¿åŠ¨å‘˜",
                "å† å†›",
                "äºšå†›",
                "å­£å†›",
            ],
            "æ•™è‚²èµ„è®¯": [
                "æ•™è‚²",
                "å­¦æ ¡",
                "æ‹›ç”Ÿ",
                "è€ƒè¯•",
                "åŸ¹è®­",
                "å­¦ä¹ ",
                "è¯¾ç¨‹",
                "æ•™æ",
            ],
        }

    def build_enhanced_analysis(self, content_data: dict) -> str:
        """æ„å»ºå¢å¼ºç‰ˆåŸºç¡€åˆ†æç»“æœ

        Args:
            content_data: å†…å®¹æ•°æ®å­—å…¸

        Returns:
            æ ¼å¼åŒ–çš„åˆ†æç»“æœ
        """
        title = content_data["title"]
        content = content_data["content"]
        url = content_data["url"]

        content_stats = self._calculate_content_statistics(content)
        content_type = self._detect_content_type(content)

        paragraphs = [p.strip() for p in content.split("\n") if p.strip()]
        key_sentences = paragraphs[:3]

        quality_indicator = self._evaluate_content_quality(content_stats["char_count"])

        result_parts = []
        result_parts.append(self._build_analysis_header())
        result_parts.append(
            self._build_basic_info(title, url, content_type, quality_indicator)
        )
        result_parts.append(self._build_statistics_info(content_stats, paragraphs))
        result_parts.append(self._build_content_summary(key_sentences))
        result_parts.append(self._build_analysis_note())

        return "".join(result_parts)

    def _build_analysis_header(self) -> str:
        """æ„å»ºåˆ†æç»“æœçš„æ ‡é¢˜éƒ¨åˆ†"""
        robot_emoji = "ğŸ¤–" if self.enable_emoji else ""
        page_emoji = "ğŸ“„" if self.enable_emoji else ""
        return f"{robot_emoji} **æ™ºèƒ½ç½‘é¡µåˆ†æ** {page_emoji}\n\n"

    def _build_basic_info(
        self, title: str, url: str, content_type: str, quality_indicator: str
    ) -> str:
        """æ„å»ºåˆ†æç»“æœçš„åŸºæœ¬ä¿¡æ¯éƒ¨åˆ†"""
        info_emoji = "ğŸ“" if self.enable_emoji else ""

        basic_info = []
        if self.enable_emoji:
            basic_info.append(f"**{info_emoji} åŸºæœ¬ä¿¡æ¯**\n")
        else:
            basic_info.append("**åŸºæœ¬ä¿¡æ¯**\n")

        basic_info.append(f"- **æ ‡é¢˜**: {title}\n")
        basic_info.append(f"- **é“¾æ¥**: {url}\n")
        basic_info.append(f"- **å†…å®¹ç±»å‹**: {content_type}\n")
        basic_info.append(f"- **è´¨é‡è¯„ä¼°**: {quality_indicator}\n\n")

        return "".join(basic_info)

    def _build_statistics_info(self, content_stats: dict, paragraphs: list) -> str:
        """æ„å»ºåˆ†æç»“æœçš„ç»Ÿè®¡ä¿¡æ¯éƒ¨åˆ†"""
        if not self.enable_statistics:
            return ""

        stats_emoji = "ğŸ“Š" if self.enable_emoji else ""

        stats_info = []
        if self.enable_emoji:
            stats_info.append(f"**{stats_emoji} å†…å®¹ç»Ÿè®¡**\n")
        else:
            stats_info.append("**å†…å®¹ç»Ÿè®¡**\n")

        stats_info.append(f"- å­—ç¬¦æ•°: {content_stats['char_count']:,}\n")
        stats_info.append(f"- æ®µè½æ•°: {len(paragraphs)}\n")
        stats_info.append(f"- è¯æ•°: {content_stats['word_count']:,}\n\n")

        return "".join(stats_info)

    def _build_content_summary(self, key_sentences: list) -> str:
        """æ„å»ºåˆ†æç»“æœçš„å†…å®¹æ‘˜è¦éƒ¨åˆ†"""
        search_emoji = "ğŸ”" if self.enable_emoji else ""

        summary_info = []
        if self.enable_emoji:
            summary_info.append(f"**{search_emoji} å†…å®¹æ‘˜è¦**\n")
        else:
            summary_info.append("**å†…å®¹æ‘˜è¦**\n")

        formatted_sentences = []
        for sentence in key_sentences:
            truncated = sentence[:100] + ("..." if len(sentence) > 100 else "")
            formatted_sentences.append(f"â€¢ {truncated}")

        summary_info.append(f"{chr(10).join(formatted_sentences)}\n\n")
        return "".join(summary_info)

    def _build_analysis_note(self) -> str:
        """æ„å»ºåˆ†æç»“æœçš„åˆ†æè¯´æ˜éƒ¨åˆ†"""
        light_emoji = "ğŸ’¡" if self.enable_emoji else ""

        note_info = []
        if self.enable_emoji:
            note_info.append(f"**{light_emoji} åˆ†æè¯´æ˜**\n")
        else:
            note_info.append("**åˆ†æè¯´æ˜**\n")

        note_info.append(
            "æ­¤åˆ†æåŸºäºç½‘é¡µå†…å®¹æå–ï¼Œå¦‚éœ€æ›´æ·±å…¥çš„AIæ™ºèƒ½åˆ†æï¼Œè¯·ç¡®ä¿AstrBotå·²æ­£ç¡®é…ç½®LLMåŠŸèƒ½ã€‚\n\n"
        )
        note_info.append("*æç¤ºï¼šå®Œæ•´å†…å®¹é¢„è§ˆè¯·æŸ¥çœ‹åŸå§‹ç½‘é¡µ*")

        return "".join(note_info)

    def _evaluate_content_quality(self, char_count: int) -> str:
        """è¯„ä¼°å†…å®¹è´¨é‡"""
        if char_count > 5000:
            return "å†…å®¹è¯¦å®"
        elif char_count > 1000:
            return "å†…å®¹ä¸°å¯Œ"
        else:
            return "å†…å®¹ç®€æ´"